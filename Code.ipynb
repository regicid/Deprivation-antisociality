{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the paper \"Why do inequality and deprivation produce high crime and low trust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the packages\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.special import binom as binom_coef\n",
    "import multiprocessing as mtp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set initial values for the environment parameters\n",
    "x = 1 # investment in cooperation\n",
    "Sigma = 5 # variance of states in the population\n",
    "u = 2 # mean state in the population\n",
    "r = 0.9 # Social immobility\n",
    "a = 1.2 # Cooperation efficiency\n",
    "penalty = 5 # Fitness imapct of being under the desperation threshold\n",
    "possible_states = np.round(np.linspace(-50,50,1001),1) # Discrete pace of the possible state values (from -50 to 50)\n",
    "risk_of_stealing = 1/3 # Probability of being punished when trying to exploit\n",
    "success_steal_prob = (1-risk_of_stealing)\n",
    "punishment = 10 # Severity of punishment in fitness units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the function for the dynamic programming, with some subfunctions first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a discretized normal distribution\n",
    "# It returns the probabilities of being at state x (which can be a vector),\n",
    "# if the expectancy is loc (also possibly a vector) and the s.d. scale\n",
    "def norm_distrib(x,loc,scale=np.sqrt(1-r**2)*Sigma):\n",
    "    x = np.array(x)\n",
    "    loc = np.array(loc)\n",
    "    x = np.tile(x,(loc.size,1))\n",
    "    loc = np.tile(loc,(loc.size,1))\n",
    "    z = (scale/np.sqrt(2*np.pi))*np.exp(-(x-loc.T)**2/(2*scale**2))\n",
    "    return z/z.sum(1,keepdims=1)\n",
    "\n",
    "# This function creates a probability transition matrix :\n",
    "# it gives, for each state value, the probability to reach any other state value \n",
    "#(\"modif\" is the increment due to the agent's action)\n",
    "def probas(modif):\n",
    "    z = (norm_distrib(x = possible_states,loc = r*possible_states + (1-r)*u + modif,scale = np.sqrt(1-r**2)*Sigma))\n",
    "    return(z)\n",
    "\n",
    "#This function is just a shortcut to transform a state value into its position in the vector \"possible_states\"\n",
    "def as_state(state):\n",
    "    return(np.where(possible_states==state)[0][0])\n",
    "\n",
    "# This is the crucial function: it runs a dynamic programming algorithm to compute the optimal decisions for given parameters\n",
    "# p is the probability of being exploited\n",
    "# T is the number of iterations (or the terminal time in dynamic programming slang)\n",
    "def dyn_prog(p,T=100):\n",
    "    # We first associate each action with a transition probability matrix\n",
    "    PROBAS_COOPERATE = p*probas(-x) + (1-p)*probas((a-1)*x)\n",
    "    PROBAS_STEAL = (1-success_steal_prob)*probas(-punishment*x) + success_steal_prob*probas(5*x)\n",
    "    PROBAS_HIDE = probas(0)\n",
    "    # We initiate empty arrays to record, for each state and each time, the optimal actions\n",
    "    optimal_decisions = np.empty((T,possible_states.size), dtype='int8')\n",
    "    # Idem for the fitness values\n",
    "    Fitness = np.empty((T+1,possible_states.size))\n",
    "    # This function search, in time t, the fitness values for every state\n",
    "    def fitness(t):\n",
    "        return (Fitness[t,]-(possible_states<0)*penalty).clip(0,)\n",
    "    # We initiate the fitness vector in the terminal time\n",
    "    Fitness[T,] = (50+possible_states)/2\n",
    "    for t in reversed(range(T)):             \n",
    "        # For each of the three actions, we compute a vector giving the expected fitness at each state\n",
    "        s = np.dot(PROBAS_STEAL,fitness(t+1))\n",
    "        h = np.dot(PROBAS_HIDE,fitness(t+1))\n",
    "        c = np.dot(PROBAS_COOPERATE,fitness(t+1))\n",
    "        # We combine the three payoffs vectors\n",
    "        payoffs = np.array([s,h,c])\n",
    "        # We compare the values at each state\n",
    "        Fitness[t,] = np.max(payoffs,axis=0) # the max becomes the fitness value at this state in time t\n",
    "        optimal_decisions[t,] = np.argmax(payoffs,axis=0) # the argmax is the optimal decision\n",
    "    return(optimal_decisions[0],p,Fitness[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the apply function gives you the optimal reaction norm for given parameters: each possible state value is associated with an optimal decision. We'll now use it to display the optimal decisions depending on the state and the social trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4eae4d95f446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current resources (s)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cmap' is not defined"
     ]
    }
   ],
   "source": [
    "a = 1.2\n",
    "r = 0.9\n",
    "u = 2\n",
    "Sigma = 1\n",
    "x = 1\n",
    "P = np.arange(0,201)/800 # We'll plot the optimal decisions, for values of p going from 0 to 0.25\n",
    "Decisions = np.empty(shape = (P.size,possible_states.size))\n",
    "for i,j in enumerate(P):\n",
    "    opt_dec = dyn_prog(p = j,T = 30)[0]\n",
    "    Decisions[i,] = opt_dec\n",
    "\n",
    "# Some graphic functions to plot properly the results    \n",
    "def cmap_discretize(cmap, N):\n",
    "    #Return a discrete colormap from the continuous colormap cmap.\n",
    "    if type(cmap) == str:\n",
    "        cmap = plt.get_cmap(cmap)\n",
    "    colors_i = np.concatenate((np.linspace(0, 1., N), (0.,0.,0.,0.)))\n",
    "    colors_rgba = cmap(colors_i)\n",
    "    indices = np.linspace(0, 1., N+1)\n",
    "    cdict = {}\n",
    "    for ki,key in enumerate(('red','green','blue')):\n",
    "        cdict[key] = [ (indices[i], colors_rgba[i-1,ki], colors_rgba[i,ki]) for i in range(N+1) ]\n",
    "    # Return colormap object.\n",
    "    return matplotlib.colors.LinearSegmentedColormap(cmap.name + \"_%d\"%N, cdict, 1024)\n",
    "\n",
    "cmap = sns.cubehelix_palette(n_colors=3,start=1, rot=.8, light=0.9, as_cmap=True)\n",
    "cmap = cmap_discretize(plt.cm.get_cmap('jet', 3),3)\n",
    "\n",
    "\n",
    "plt.imshow(Decisions,cmap = cmap,aspect = \"auto\")\n",
    "\n",
    "plt.xlabel(\"Current resources (s)\")\n",
    "plt.ylabel('Social trust (1-p)')\n",
    "\n",
    "plt.xticks([250,500,750],[-25,0,25])\n",
    "plt.yticks(np.linspace(0,Decisions.shape[0]-1,5),(map(str,np.round(1-np.linspace(0,np.max(P),5),2))))\n",
    "plt.xlim(250,750)\n",
    "cbar = plt.colorbar(shrink = 0.2,aspect = 3)\n",
    "cbar.set_ticks([0.33,1,1.66])\n",
    "cbar.set_ticklabels(['Exploit','Forage alone',\"Cooperate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 50 \n",
    "N = 100\n",
    "n = 5\n",
    "\n",
    "def States(Z):\n",
    "    return([Z.Pop[i].state for i in range(len(Z.Pop))])\n",
    "def Trusts(Z):\n",
    "    return([1-Z.Pop[i].social_distrust for i in range(len(Z.Pop))])\n",
    "def Types(P):\n",
    "    return([P.Pop[i].type for i in range(len(P.Pop))])\n",
    "def Enforce(P):\n",
    "    return([P.Pop[i].enforce for i in range(len(P.Pop))])\n",
    "\n",
    "\n",
    "def distrust(f,q):\n",
    "    if f == precision:\n",
    "        return 1-q/2\n",
    "    est = np.round(f/precision*N*n)\n",
    "    p = 1- binom_coef(N*n-est-1,n-1)/binom_coef(N*n-1,n-1)\n",
    "    return(p*(1-q/2))\n",
    "def enforce_belief(q):\n",
    "    if q == precision:\n",
    "        return 1\n",
    "    est = round(q/precision*N*n) \n",
    "    return(1 - binom_coef(N*n-est-1,n-1)/binom_coef(N*n-1,n-1))\n",
    "\n",
    "def create(params):\n",
    "    file = f\"./Desktop/Nettle/Library/a={a}_punish={punishment}_risk={risk}p={params[0]}_q={params[1]}_u={u}_r={r}_Sigma={Sigma}_precision={precision}_n={n}_N={N}\"\n",
    "    if (not os.path.exists(file+\"_D.npy\")) or (not os.path.exists(file+\"_E.npy\")):\n",
    "        D = dyn_prog2(params,speeding=False)\n",
    "        return(params,D[0],D[1])\n",
    "    else:\n",
    "        return params,a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
